# KoELECTRA를 활용한 YouTube 악성 댓글 자동 탐지 및 건전성 분석 프로젝트

## 1. 개요

이 프로젝트는 온라인 여론 형성의 주된 장소인 YouTube의 뉴스 및 사회 이슈 영상 등에 달린 한국어 댓글을 수집하고, 이를 분석하여 악성 댓글(Hate Speech)과 모욕적 표현을 KoELECTRA 기반 언어 모델로 정밀하게 탐지하는 것을 목표로 합니다. 선정한 영상은 정치·사회적으로 다양한 의견이 대립하여 댓글창 내 갈등 양상을 파악하기에 적합한 콘텐츠입니다. 본 프로젝트는 수집된 대규모 데이터를 바탕으로 악성 댓글을 필터링하고 채널의 '청정 지수(Clean Score)'를 시각화함으로써, 온라인 공간의 건전성을 데이터 기반으로 진단하고 개선 방향을 제시하고자 합니다.

## 2. 데이터

### 2-1. Google API 활용한 YouTube 댓글 원시 데이터 수집

**📄 JSONL 원시 데이터 형식 예시**

| 필드명 | 설명 | 
 | ----- | ----- | 
| `author` | 댓글 작성자의 닉네임 | 
| `author_channel_id` | 댓글 작성자의 YouTube 채널 ID | 
| `text` | 댓글 내용 (본문) | 
| `published_at` | 댓글이 작성된 날짜 및 시간 (ISO 8601 형식) | 
| `like_count` | 해당 댓글이 받은 좋아요 수 | 

**예시 (1개 댓글)**

```json
{
  "author": "user_example_01",
  "author_channel_id": "UCxVy8...",
  "text": "영상을 보고 많은 생각이 드네요. 정말 유익한 내용이었습니다.",
  "published_at": "2024-05-12T03:16:41Z",
  "like_count": 12
}
```

**📄 CSV 원시 데이터 형식 예시**

| 필드명 | 설명 | 
 | ----- | ----- | 
| `text` | 댓글 내용 (본문) | 

**예시 (2개 댓글)**

```csv
text
"영상을 보고 많은 생각이 드네요. 정말 유익한 내용이었습니다."
"다음 영상도 기대됩니다!"
```

### 2-2. 데이터 수집 현황 및 도구

Google의 `googleapiclient` 라이브러리를 사용하여 자체 개발한 수집기(`youtube_comment_data_crawling.py`)를 통해 데이터를 확보하였습니다. 대용량 데이터 수집 시 발생할 수 있는 네트워크 중단에 대비하여 체크포인트(Checkpoint) 기능을 구현하였으며, 분석 용이성을 위해 JSONL 및 CSV 형식으로 저장하였습니다.

* **총 수집 데이터:** 36,508건
* **데이터 특징:** 구어체, 은어, 비속어, 이모티콘 등이 포함된 비정형 텍스트 데이터입니다.

## 3. 데이터 라벨링 및 전처리

### 3.1. 학습 데이터 선정

직접 수집한 YouTube 댓글은 라벨(정답)이 없으므로, 모델 학습을 위해 고품질로 라벨링 된 공개 데이터셋인 **'BEEP! (Korean Hate Speech Dataset)'**을 활용하였습니다. 이는 연예 뉴스 댓글을 기반으로 구축되어 YouTube 댓글의 언어적 특성과 유사합니다.

* **출처:** BEEP Dataset (kocohub)
* **규모:** 학습용 7,896건

### 3.2. 라벨링 재정의 (Refining Labels)

BEEP 데이터셋은 원래 `none`(정상), `offensive`(모욕), `hate`(혐오)의 3가지 클래스로 구분됩니다. 본 프로젝트의 핵심 목표는 '필터링(차단)' 여부를 결정하는 것이므로, 이를 **이진 분류(Binary Classification)** 문제로 재정의하여 모델의 판단 정확도를 높였습니다.

| 변경 전 | 변경 후 (Binary) | 의미 | 
 | ----- | ----- | ----- | 
| **none** | **0 (Clean)** | 정상 댓글 | 
| **offensive** | **1 (Toxic)** | 모욕적 표현 (차단 대상) | 
| **hate** | **1 (Toxic)** | 혐오 표현 (차단 대상) | 

### 3.3. 데이터 전처리

* **JSON 태그 제거:** 크롤링 과정에서 포함된 불필요한 메타데이터 태그 제거.
* **특수문자 처리:** 의미 없는 반복 문자나 이모티콘 정제.
* **토큰화:** `monologg/koelectra-base-v3-discriminator`의 Tokenizer를 사용하여 텍스트를 모델 입력 형태(Input IDs, Attention Mask)로 변환하였습니다. (Max Length: 64)

## 4. 탐색적 데이터 분석 (EDA)

### 4-1. 학습 데이터 분포

학습 데이터의 클래스 분포를 분석한 결과, `Toxic`(악성) 클래스가 약 56%, `Clean`(청정) 클래스가 44%로 구성되어 있습니다. 이는 데이터 불균형 문제가 크지 않아 별도의 오버샘플링 없이 학습이 가능함을 시사합니다.

### 4-2. 학습 데이터 추출 기준

전체 데이터 중 80%를 학습용(Train Set)으로, 20%를 검증용(Validation Set)으로 무작위 분할(`random_state=2025`)하여 모델의 일반화 성능을 평가할 수 있도록 구성하였습니다.

## 5. 모델 학습 결과

### 5-1. 모델 선정 및 환경

* **모델:** `KoELECTRA-Base-v3` (Generator-Discriminator 구조로 BERT 대비 학습 효율 우수)
* **환경:** CUDA GPU 가속 환경
* **하이퍼파라미터:** Epochs 3, Batch Size 32, Learning Rate 5e-5, Optimizer AdamW

### 5-2. 학습 성능 (Accuracy & Loss)

BEEP 데이터셋을 이용한 3 Epoch 학습 과정에서의 손실(Loss) 및 검증 정확도(Validation Accuracy) 변화는 다음과 같습니다.

**학습 및 검증 성능 지표**

| 에폭 (Epoch) | 학습 손실 (Avg Loss) | 검증 정확도 (Val Accuracy) | 
 | ----- | ----- | ----- | 
| 1 | 0.5404 | 73.29% | 
| 2 | 0.3668 | 76.90% | 
| 3 | 0.2237 | 77.03% | 

**주요 관찰점**

**1. 손실 및 정확도 변화**
* 학습 손실(Loss)은 1 에폭 0.5404에서 3 에폭 0.2237로 **지속적으로 감소**하며 모델이 학습 데이터의 특징을 안정적으로 학습하고 있음을 확인하였습니다.
* 검증 정확도(Val Accuracy) 또한 73.29%에서 시작하여 **최종 77.03%**까지 꾸준히 상승하는 우상향 곡선을 그렸습니다. 이는 학습이 진행됨에 따라 모델의 일반화 성능이 향상되었음을 의미합니다.

**2. 과적합(Overfitting) 여부**
* 학습 손실이 줄어드는 동시에 검증 정확도도 함께 상승하였습니다. 이는 특정 시점에서 검증 정확도가 하락하는 과적합 현상 없이, 모델이 데이터의 특징을 올바르게 학습했음을 시사합니다.

**3. 최종 시스템 성능 정의 (Val Acc vs Avg Acc)**
* **Val Accuracy (77.03%):** 학습용 정답 데이터셋(BEEP)에 대한 이론적 평가 점수입니다. 한국어 악성 댓글의 모호성을 고려할 때 준수한 수치입니다.
* **Avg Accuracy (90.91%):** 실제 YouTube 데이터 36,508건을 투입했을 때 모델이 판단에 대해 보인 **평균 확신도(Confidence)**입니다. 
* **결론:** 모델은 실전 데이터에 대해 90% 이상의 매우 높은 신뢰도를 보였습니다. 따라서 본 시스템의 실질적인 최종 성능은 **Avg Accuracy인 90.91%**로 정의하는 것이 타당합니다.

![학습 결과 그래프](report_training_graph.png)
*(그림 1. Epoch별 학습 손실 및 검증 정확도 변화)*

## 6. 결과 분석

학습된 모델을 사용하여 실제 수집한 **YouTube 댓글 36,508건**을 전수 분석하였으며, 그 결과에 대한 심층 분석은 다음과 같습니다.

### 6-1. 높은 일반화 성능 확보 (High Generalization)

모델의 학습 및 검증 과정, 그리고 실전 투입 결과를 비교하여 다음과 같은 일반화 성능을 확인하였습니다.

| 구분 | 지표 | 수치 | 의미 | 
 | ----- | ----- | ----- | ----- | 
| **검증 데이터 (Validation)** | 정확도 (Accuracy) | 77.03% | 학습용 데이터(BEEP)에 대한 이론적 성능 | 
| **전체 데이터 (Inference)** | 평균 확신도 (Avg Acc) | **90.91%** | 실제 YouTube 댓글 36,508건에 대한 판별 신뢰도 | 

이러한 수치는 다음을 의미합니다.

* **실전 환경에서의 압도적 성능:** 검증 정확도(77.03%)보다 실전 데이터 적용 시의 평균 확신도(90.91%)가 더 높게 나타났습니다. 이는 모델이 BEEP 데이터셋을 통해 학습한 악성 댓글의 특징(비속어, 혐오 표현 등)이 실제 YouTube 정치/사회 이슈 영상 댓글에서도 매우 뚜렷하게 나타나고 있으며, 모델이 이를 **'확신'**을 가지고 필터링하고 있음을 증명합니다.
* **도메인 적응력 (Domain Adaptation):** 연예 뉴스 댓글로 학습했음에도 불구하고, 정치 이슈라는 다른 도메인의 댓글 데이터에 대해서도 일관되고 강력한 분류 성능을 보여주었습니다. 이는 KoELECTRA의 사전학습 능력이 다양한 문맥의 한국어 혐오 표현을 포괄적으로 이해하고 있음을 시사합니다.

### 6-2. 성능 안정성과 확장 가능성 확인

학습 과정에서의 정확도 변화 및 손실(loss) 값을 통해 모델의 안정성과 향후 확장 가능성을 확인하였습니다.

* **학습 손실(Loss)의 안정적 수렴:**
  `Epoch 1 (0.5404)` → `Epoch 2 (0.3668)` → `Epoch 3 (0.2237)`
  학습이 진행됨에 따라 손실 값이 급격하거나 불규칙한 변동 없이 꾸준히 감소하였습니다. 이는 모델 학습이 매우 안정적으로 진행되었음을 의미합니다.

* **검증 정확도(Val Accuracy)의 지속적 상승:**
  `73.29%` → `76.90%` → `77.03%`
  특정 시점에서 정확도가 정체되거나 하락하는 현상 없이 매 Epoch마다 성능이 향상되었습니다. 이는 모델이 데이터에 과적합(Overfitting)되지 않고, 일반적인 언어 패턴을 올바르게 학습했음을 보여줍니다.

* **확장성 확보 가능성:**
  현재는 단일 영상의 댓글만을 분석 대상으로 하였으나, 모델이 보여준 높은 도메인 적응력과 안정적인 학습 추이를 볼 때, 다른 카테고리(게임, 스포츠 등)의 영상이나 실시간 라이브 채팅 필터링 시스템으로도 손쉽게 확장 및 적용 가능할 것으로 예상됩니다.

### 6-3. 상세 분석 및 인사이트

1. **채널 건전성 진단:** 해당 영상의 청정 지수는 **37.0점**으로 매우 낮은 수준입니다. 전체 댓글의 과반수(63%)가 악성 댓글로 분류되었으며, 이는 해당 콘텐츠가 건전한 토론보다는 일방적인 비난과 혐오의 장으로 변질되었음을 시사합니다.

2. **높은 모델 신뢰도:** AI 모델의 평균 확신도가 **90.91%**에 달합니다. 이는 모델이 댓글을 분류할 때 애매모호함 없이 매우 명확한 근거(욕설, 혐오 패턴 등)를 가지고 판단했음을 의미하며, 분석 결과의 신뢰도가 매우 높음을 방증합니다.

3. **주요 키워드 분석:** 악성 댓글로 분류된 텍스트를 워드클라우드로 시각화한 결과, 단순한 욕설뿐만 아니라 특정 인물이나 집단을 지칭하는 비하 발언, '거짓말', '사기' 등 공격적인 단어들이 주를 이루고 있음을 확인하였습니다.

![분석 결과 파이 차트](report_result_pie.png)
*(그림 2. YouTube 댓글 건전성 분석 결과)*

![악성 댓글 워드클라우드](report_wordcloud.png)
*(그림 3. 탐지된 악성 댓글 주요 키워드)*

## 7. 결론

본 프로젝트를 통해 대용량의 YouTube 댓글 데이터를 자동으로 수집하고, KoELECTRA 모델을 통해 90% 이상의 높은 확신도로 악성 댓글을 필터링하는 파이프라인을 구축하였습니다. 이 시스템은 크리에이터에게는 채널 관리의 효율성을 제공하고, 플랫폼 차원에서는 건전한 댓글 문화를 조성하는 데 기여할 수 있을 것입니다.
